{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00826403",
      "metadata": {
        "id": "00826403"
      },
      "source": [
        "# ðŸ“ˆ PySpark Market Tick Simulation & Analysis\n",
        "This notebook simulates live market tick data and performs real-time analysis using PySpark â€” without needing Kafka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "09d1af12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09d1af12",
        "outputId": "b13a9a23-b178-4c27-d551-6518f0f3af34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "âœ… Spark session ready\n"
          ]
        }
      ],
      "source": [
        "# âœ… Step 1: Install & Initialize Spark\n",
        "# # Install if not already\n",
        "!pip install pyspark findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MarketTickSimulation\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"âœ… Spark session ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6eeb949b",
      "metadata": {
        "id": "6eeb949b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# âœ… Step 2: Define Schema & Simulated Tick Generator\n",
        "#\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
        "import pandas as pd\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"symbol\", StringType(), True),\n",
        "    StructField(\"bid\", DoubleType(), True),\n",
        "    StructField(\"ask\", DoubleType(), True),\n",
        "    StructField(\"timestamp\", TimestampType(), True),\n",
        "])\n",
        "\n",
        "def generate_tick(symbol=\"XAUUSD\"):\n",
        "    bid = round(random.uniform(1850, 1860), 3)\n",
        "    ask = round(bid + random.uniform(0.01, 0.05), 3)\n",
        "    ts = datetime.datetime.now()\n",
        "    return [(symbol, bid, ask, ts)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4ce7d20d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ce7d20d",
        "outputId": "d62c27eb-9815-4a77-eab8-8bb6c3b42c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+--------+--------------------------+\n",
            "|symbol|bid   |ask     |timestamp                 |\n",
            "+------+------+--------+--------------------------+\n",
            "|XAUUSD|1858.1|1858.122|2025-07-01 14:43:34.232424|\n",
            "+------+------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.856|1856.873|2025-07-01 14:43:56.394726|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.856|1856.873|2025-07-01 14:43:56.394726|\n",
            "|XAUUSD|1853.905|1853.932|2025-07-01 14:43:57.896101|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.856|1856.873|2025-07-01 14:43:56.394726|\n",
            "|XAUUSD|1853.905|1853.932|2025-07-01 14:43:57.896101|\n",
            "|XAUUSD|1854.747|1854.764|2025-07-01 14:43:59.318023|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.856|1856.873|2025-07-01 14:43:56.394726|\n",
            "|XAUUSD|1853.905|1853.932|2025-07-01 14:43:57.896101|\n",
            "|XAUUSD|1854.747|1854.764|2025-07-01 14:43:59.318023|\n",
            "|XAUUSD|1857.785|1857.804|2025-07-01 14:44:00.851085|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.856|1856.873|2025-07-01 14:43:56.394726|\n",
            "|XAUUSD|1853.905|1853.932|2025-07-01 14:43:57.896101|\n",
            "|XAUUSD|1854.747|1854.764|2025-07-01 14:43:59.318023|\n",
            "|XAUUSD|1857.785|1857.804|2025-07-01 14:44:00.851085|\n",
            "|XAUUSD|1856.263|1856.281|2025-07-01 14:44:02.269633|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n",
            "+------+--------+--------+--------------------------+\n",
            "|symbol|bid     |ask     |timestamp                 |\n",
            "+------+--------+--------+--------------------------+\n",
            "|XAUUSD|1858.1  |1858.122|2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.527|1856.56 |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.924|1852.935|2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.677|1858.687|2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.856|1856.873|2025-07-01 14:43:56.394726|\n",
            "|XAUUSD|1853.905|1853.932|2025-07-01 14:43:57.896101|\n",
            "|XAUUSD|1854.747|1854.764|2025-07-01 14:43:59.318023|\n",
            "|XAUUSD|1857.785|1857.804|2025-07-01 14:44:00.851085|\n",
            "|XAUUSD|1856.263|1856.281|2025-07-01 14:44:02.269633|\n",
            "|XAUUSD|1851.345|1851.384|2025-07-01 14:44:03.776444|\n",
            "+------+--------+--------+--------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# âœ… Step 3: Simulate Live Stream (10 ticks)\n",
        "\n",
        "import time\n",
        "from pyspark.sql import Row\n",
        "\n",
        "live_ticks = []\n",
        "\n",
        "# Simulate 10 ticks\n",
        "for i in range(10):\n",
        "    tick = generate_tick()[0]\n",
        "    live_ticks.append(tick)\n",
        "\n",
        "    # Convert to Spark DataFrame\n",
        "    tick_df = spark.createDataFrame(live_ticks, schema=schema)\n",
        "    tick_df.show(truncate=False)\n",
        "\n",
        "    # Optional: store or analyze here\n",
        "\n",
        "    time.sleep(1)  # Simulate real-time tick\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5f7fede8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f7fede8",
        "outputId": "36f1bc5e-f236-4581-d0eb-5e1948ab6457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+------------------+----------+--------------------------+\n",
            "|symbol|mid_price         |ma_5              |pct_change|timestamp                 |\n",
            "+------+------------------+------------------+----------+--------------------------+\n",
            "|XAUUSD|1858.1109999999999|1858.1109999999999|NULL      |2025-07-01 14:43:34.232424|\n",
            "|XAUUSD|1856.5435         |1857.3272499999998|-0.0844   |2025-07-01 14:43:51.099475|\n",
            "|XAUUSD|1852.9295         |1855.8613333333333|-0.1947   |2025-07-01 14:43:52.81258 |\n",
            "|XAUUSD|1858.6819999999998|1856.5665         |0.3105    |2025-07-01 14:43:54.940799|\n",
            "|XAUUSD|1856.8645000000001|1856.6261         |-0.0978   |2025-07-01 14:43:56.394726|\n",
            "|XAUUSD|1853.9185         |1855.7876         |-0.1587   |2025-07-01 14:43:57.896101|\n",
            "|XAUUSD|1854.7555         |1855.4299999999998|0.0451    |2025-07-01 14:43:59.318023|\n",
            "|XAUUSD|1857.7945         |1856.4029999999998|0.1638    |2025-07-01 14:44:00.851085|\n",
            "|XAUUSD|1856.272          |1855.9209999999998|-0.082    |2025-07-01 14:44:02.269633|\n",
            "|XAUUSD|1851.3645000000001|1854.821          |-0.2644   |2025-07-01 14:44:03.776444|\n",
            "+------+------------------+------------------+----------+--------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# âœ… Step 4: Compute mid price, moving avg & change%\n",
        "\n",
        "from pyspark.sql.functions import col, avg, lag, expr\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "window_spec = Window.orderBy(\"timestamp\").rowsBetween(-4, 0)\n",
        "window_spec_lag = Window.orderBy(\"timestamp\") # Define a separate window spec for lag\n",
        "\n",
        "tick_df = spark.createDataFrame(live_ticks, schema=schema)\n",
        "\n",
        "tick_df = tick_df \\\n",
        "    .withColumn(\"mid_price\", (col(\"bid\") + col(\"ask\")) / 2) \\\n",
        "    .withColumn(\"ma_5\", avg(\"mid_price\").over(window_spec)) \\\n",
        "    .withColumn(\"prev_price\", lag(\"mid_price\", 1).over(window_spec_lag)) \\\n",
        "    .withColumn(\"pct_change\", expr(\"ROUND((mid_price - prev_price)/prev_price * 100, 4)\"))\n",
        "\n",
        "tick_df.select(\"symbol\", \"mid_price\", \"ma_5\", \"pct_change\", \"timestamp\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Portfolio VaR Calculation Using PySpark\n",
        "\n",
        "\n",
        "Weâ€™ll simulate portfolio prices for multiple assets, compute daily returns, and calculate a simple Historical Simulation VaR.\n",
        "\n",
        "##ðŸ”¹ Step 1: Simulate portfolio price data (batch)"
      ],
      "metadata": {
        "id": "pXXsdl9Oct25"
      },
      "id": "pXXsdl9Oct25"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Start SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PortfolioVaR\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"SparkSession started\")\n",
        "\n",
        "# Step 2: Import types\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "# Step 3: Prepare your simulated data\n",
        "symbols = [\"AAPL\", \"GOOG\", \"TSLA\"]\n",
        "days = 30\n",
        "price_data = []\n",
        "\n",
        "base_prices = {\"AAPL\": 150, \"GOOG\": 2700, \"TSLA\": 700}\n",
        "start_date = datetime.date.today() - datetime.timedelta(days=days)\n",
        "\n",
        "for day in range(days):\n",
        "    date = start_date + datetime.timedelta(days=day)\n",
        "    for symbol in symbols:\n",
        "        base = base_prices[symbol]\n",
        "        price = base * (1 + random.gauss(0, 0.01))\n",
        "        price_data.append((symbol, float(price), datetime.datetime.combine(date, datetime.time())))\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"symbol\", StringType(), True),\n",
        "    StructField(\"price\", DoubleType(), True),\n",
        "    StructField(\"date\", TimestampType(), True),\n",
        "])\n",
        "\n",
        "prices_df = spark.createDataFrame(price_data, schema=schema)\n",
        "prices_df.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LOXgAhcZE8",
        "outputId": "4d00fd7d-ea52-463f-8606-e1f232edc2d0"
      },
      "id": "32LOXgAhcZE8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession started\n",
            "+------+------------------+-------------------+\n",
            "|symbol|price             |date               |\n",
            "+------+------------------+-------------------+\n",
            "|AAPL  |149.27904062346965|2025-06-01 00:00:00|\n",
            "|GOOG  |2694.148370538865 |2025-06-01 00:00:00|\n",
            "|TSLA  |694.5206460117872 |2025-06-01 00:00:00|\n",
            "|AAPL  |149.47861159215623|2025-06-02 00:00:00|\n",
            "|GOOG  |2690.5589791564244|2025-06-02 00:00:00|\n",
            "+------+------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        ">ðŸ”¹ Step 2: Calculate daily returns per asset\n",
        "\n"
      ],
      "metadata": {
        "id": "2Ggjhe-zcmm9"
      },
      "id": "2Ggjhe-zcmm9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Window spec by symbol ordered by date\n",
        "window_spec = Window.partitionBy(\"symbol\").orderBy(\"date\")\n",
        "\n",
        "returns_df = prices_df \\\n",
        "    .withColumn(\"prev_price\", lag(\"price\").over(window_spec)) \\\n",
        "    .withColumn(\"return\", (col(\"price\") - col(\"prev_price\")) / col(\"prev_price\")) \\\n",
        "    .na.drop()\n",
        "\n",
        "returns_df.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30H9GP6Dcm47",
        "outputId": "88389ee7-0370-49f8-d6a9-80d76f61262a"
      },
      "id": "30H9GP6Dcm47",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+-------------------+------------------+---------------------+\n",
            "|symbol|price             |date               |prev_price        |return               |\n",
            "+------+------------------+-------------------+------------------+---------------------+\n",
            "|AAPL  |149.47861159215623|2025-06-02 00:00:00|149.27904062346965|0.001336898789361564 |\n",
            "|AAPL  |148.8572192194209 |2025-06-03 00:00:00|149.47861159215623|-0.004157065456499972|\n",
            "|AAPL  |149.60441201818296|2025-06-04 00:00:00|148.8572192194209 |0.005019526783317565 |\n",
            "|AAPL  |148.26196167995175|2025-06-05 00:00:00|149.60441201818296|-0.008973333875126896|\n",
            "|AAPL  |149.03475129817176|2025-06-06 00:00:00|148.26196167995175|0.005212325598984036 |\n",
            "+------+------------------+-------------------+------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”¹ Step 3: Simulate portfolio weights & calculate portfolio returns"
      ],
      "metadata": {
        "id": "mPlU9o62c_91"
      },
      "id": "mPlU9o62c_91"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as spark_sum\n",
        "from pyspark.sql import functions as F # Import PySpark SQL functions with alias F\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Assign fixed weights for demo\n",
        "weights = {\"AAPL\": 0.4, \"GOOG\": 0.4, \"TSLA\": 0.2}\n",
        "\n",
        "# Add weight column\n",
        "weights_expr = F.create_map([F.lit(x) for x in sum(weights.items(), ())])\n",
        "\n",
        "weighted_returns_df = returns_df.withColumn(\"weight\", weights_expr[col(\"symbol\")])\n",
        "weighted_returns_df = weighted_returns_df.withColumn(\"weighted_return\", col(\"return\") * col(\"weight\"))\n",
        "\n",
        "# Aggregate portfolio returns by date\n",
        "portfolio_returns_df = weighted_returns_df.groupBy(\"date\").agg(spark_sum(\"weighted_return\").alias(\"portfolio_return\"))\n",
        "portfolio_returns_df.orderBy(\"date\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJypaiEMc7i1",
        "outputId": "ccb688b3-e5b9-4d9c-f50b-b82554e29949"
      },
      "id": "EJypaiEMc7i1",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+---------------------+\n",
            "|date               |portfolio_return     |\n",
            "+-------------------+---------------------+\n",
            "|2025-06-02 00:00:00|7.565603612609529E-4 |\n",
            "|2025-06-03 00:00:00|-8.357450757989856E-4|\n",
            "|2025-06-04 00:00:00|0.008064735609741759 |\n",
            "|2025-06-05 00:00:00|-0.006473728662978609|\n",
            "|2025-06-06 00:00:00|-0.002960881131908823|\n",
            "+-------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ”¹ Step 4: Calculate Historical VaR at 95% confidence level"
      ],
      "metadata": {
        "id": "aaX9uEXVdB6Y"
      },
      "id": "aaX9uEXVdB6Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect portfolio returns as a list for VaR calc (small demo)\n",
        "returns_list = [row[\"portfolio_return\"] for row in portfolio_returns_df.collect()]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate 5th percentile loss (VaR)\n",
        "var_95 = np.percentile(returns_list, 5)\n",
        "\n",
        "print(f\"ðŸ“‰ Portfolio 1-day 95% VaR estimate: {var_95:.4%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAGg6_p5c9RN",
        "outputId": "42d0267a-de0b-4dcd-bc8a-0b07b1fbbaac"
      },
      "id": "QAGg6_p5c9RN",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‰ Portfolio 1-day 95% VaR estimate: -1.3861%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}